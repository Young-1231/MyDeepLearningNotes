# Parts
## Optimizer
---
### 参考资料
> [骆梁宸的知乎文章](https://zhuanlan.zhihu.com/p/32626442)

### 引言

最优化问题是计算数学中最为重要的研究方向之一。而在深度学习领域，优化算法的选择也是一个模型的重中之重。即使在数据集和模型架构完全相同的情况下，采用不同的优化算法，也很可能导致截然不同的训练效果。

梯度下降是目前神经网络中使用最为广泛的优化算法之一。为了弥补朴素梯度下降的种种缺陷，研究者们发明了一系列变种算法，从最初的 SGD (随机梯度下降) 逐步演进到 NAdam。然而，许多学术界最为前沿的文章中，都并没有一味使用 Adam/NAdam 等公认“好用”的自适应算法，很多甚至还选择了最为初级的 SGD 或者 SGD with Momentum 等。

本文旨在梳理深度学习优化算法的发展历程，并在一个更加概括的框架之下，对优化算法做出分析和对比。

### Gradient Descent
梯度下降是指，在给定待优化的模型参数$\theta \in \mathbb{R}^d$和目标函数$J(\theta)$后，算法通过沿梯度$\nabla_\theta J(\theta)$的相反方向更新$\theta$来最小化$J(\theta)$.学习率$\eta$决定了每一时刻的更新步长。对于每一个时刻$t$,我们可以用下述步骤描述梯度下降的流程：
1. 计算目标函数关于参数的梯度 $$
g_t = \nabla_\theta J(\theta)
$$
2. 根据历史梯度计算一阶和二阶动量 $$
m_t = \phi(g_1,g_2,\cdots,g_t) \\ 
v_t = \psi(g_1,g_2,\cdots,g_t)
$$
3. 更新模型参数$$
\theta_{t+1} = \theta_t - \frac{1}{\sqrt{v_t+\epsilon}}m_t
$$
其中，$\varepsilon$是平滑项，防止分母为零，通常取1e-8

### Gradient Descent和其算法变种

#### Vanilla SGD
朴素SGD最为简单，没有动量的概念，即
$$
m_t = \eta g_t \\ 
v_t = I^2 \\ 
\epsilon = 0
$$
此时，更新步骤就是最简单的$$
\theta_{i+1} = \theta_t - \eta g_t
$$
> SGD的缺点在于收敛速度慢，可能在鞍点处震荡，如何合理的选择学习率是SGD的一大难点

#### Momentum
SGD在遇到沟壑时容易陷入震荡。为此，可以为其引入动量 Momentum，加速SGD在正确方向的下降并抑制震荡
$$
m_t = \gamma m_{t-1} + \eta g_t
$$
SGD-M在原步长之上，增加了与上一时刻步长相关的$\gamma m_{t-1}$，$\gamma$通常取0.9左右。这意味参数更新方向不仅由当前的梯度决定，也与此前累积的下降方向有关。这使得参数中哪些梯度方向变化不大的维度可以加速更新，并减少梯度方向变化较大的维度上的更新幅度。由此产生了加速收敛和减小震荡的效果。

#### Nesterov Accelerated Gradient
更进一步的，人们希望下降的过程更加智能：算法能够在目标函数有增高趋势之前，减缓更新速率。
NAG即是为此而设计的，其在SGD-M的基础上进一步改进了步骤1中的梯度计算公式
$$
g_t=\nabla_{\theta} J(\theta-\gamma m_{t-1})
$$
> SGD-M的步长计算了当前梯度和动量项。然而，既然已经利用了动量项来更新，那不妨先计算下一时刻$\theta$的近似位置，并根据该未来位置计算梯度，然后使用和SGD-M中相同的方式计算步长。这种计算梯度的方式可以使算法更好的"预测未来",提前调整更新速率

#### Adagrad
SGD，SGD-M和NAG均是以相同的学习率取更新$\theta$的各个分量。而深度学习模型往往涉及大量的参数，不同参数的更新频率往往有所区别。对于更新不频繁的参数，我们希望单词步长更大，多学习一点知识；对于更新频繁的参数，我们则希望步长较小，使得学习到的参数更稳定更鲁棒，不至于被单个样本影响太多。
Adagrad算法即可达到此效果。其引入了二阶动量
$$
v_t = {\rm diag}\left(\sum\limits_{i=1}^{t}g_{i,1}^2,\sum\limits_{i=1}^t g_{i,2}^2,\cdots,\sum\limits_{i=1}^{t}g_{i,d}^2\right)
$$
其中，$v_t\in \mathbb{R}^{d\times d}$是对角矩阵，其元素$v_{t,i}$为参数第$i$维从初始时刻到时刻$t$的梯度平方和
> 此时，可以这样理解：学习率等效为$\displaystyle \frac{\eta}{\sqrt{v_t+\epsilon}}$。对于此前频繁更新过的参数，其二阶动量的对应分量的对应分量较大，学习率就较小。这一方法在稀疏数据的场景下表现很好。

#### RMSprop
在Adagrad中，$v_t$是单调递增的，使得学习率逐渐递减至零，可能导致训练过程提前结束。为了改进这一缺点，可以考虑在计算二阶动量时不累积全部历史梯度，而只关注最近某一时间窗口内的下降梯度。根据此思想。记$g_t \odot g_t = g_t^2$,有
$$
v_t = \gamma v_{t-1} + (1-\gamma)\cdot {\rm diag}(g_t^2)
$$
其二阶动量采用指数移动平均公式计算，这样即可避免二阶动量持续累积的问题。和SGD-M中的参数类似，$\gamma$通常取0.9左右

#### Adam
Adam可以认为是RMSprop和Momentum的结合。和RMSprop对二阶动量使用指数移动平均类似，Adam中对一阶动量也是指数移动平均计算。
$$
m_t = \gamma [\beta_1 m_{t-1} +(1-\beta_1)g_t] \\ 
v_t = \beta_2 v_{t-1} + (1-\beta_2)\cdot {\rm diag}(g_t^2)
$$
其中，初值 $$
m_0 = 0, v_0 = 0
$$
注意到，在迭代初始阶段，$m_t$和$v_t$有一个向初值的偏移。因此，可以对一阶和二阶动量做偏置校正(bias correction)
$$
\hat{m_t} = \frac{m_t}{1-\beta_1^t}\\
\hat{v_t} = \frac{v_t}{1-\beta_2^t}
$$
再进行更新 $$
\theta_{t+1} = \theta_t - \frac{1}{\sqrt{\hat{v_t}+\epsilon}}\hat{m_t}
$$

