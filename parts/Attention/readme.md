# Parts
## Attention

### 参考资料
[Dive into Deep Learning](http://zh.d2l.ai/chapter_attention-mechanisms/attention-cues.html)
[知乎文章](https://zhuanlan.zhihu.com/p/141876609)

### 基础内容介绍

#### 生物学中的注意力

注意力机制(Attention Mechanism)源于对人类视觉的研究。在认知科学中，

##### Two-component 框架

可追溯到19世纪90年代威廉詹姆斯。在Two Component框架中，受试者基于**非自主性提示**和**自主提示**有选择地引导注意力地焦点。
非自主性提示是基于环境中物体地突出性和易见性。同时注意力在基于自主性提示去辅助选择是将更为谨慎。
##### Another Explanation
人类视网膜的不同部位具有不同程度的信息处理能力，即敏锐度。为了合理利用有限的视觉信息处理资源，人类需要选择视觉区域中的特定部分，然后集中关注它。综上，注意力机制主要有两个方面:
* 决定需要关注输入的哪部分
* 分配有限的信息处理资源给重要的部分

#### 计算机视觉中的注意力机制
在计算机视觉领域，注意力机制被引来进行视觉信息处理。注意力是一种机制，或者方法论，实际上并无严格的数学定义。比如，传统的局部图像特征提取，显著性检测，滑动窗口方法等都可以看作是一种注意力机制。而在nn中，注意力模块通常是一个额外的神经网络，能够硬性选择输入的某些部分，或者给输入的不同部分分配不同的权重。

##### 只使用非自主性提示
将选择偏向于感官输入，我们可以简单地使用参数化的全连接层，甚至是非参数化的`max pool` 或`avg pool`
##### 包含自主性提示
"是否包含自主性提示"将注意力机制与全连接层或汇聚层区别开。在注意力机制的背景下，我们将自主性提示称为**查询(query)**。对于给定的**query**,注意力机制通过**注意力汇聚**(attention pooling)将选择引导至**感官输入**(sensory inputs, 例如中间特征表示).
在注意力机制中，这些感官属于被称为**值**(value)。每一个value都和key配对，这可以想象为感官输入的非自主性提示。我们可以设计attention pooling, 以便给定的query可以与key进行匹配，这将引导得出最匹配的value。

----
#### TODOlist
- [ ] 认知科学, 深入了解 Two-component框架



<details>
<summary>菜单</summary>
</details>